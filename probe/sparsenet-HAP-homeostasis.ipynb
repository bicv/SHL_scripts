{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homeostasis Ã -la-SparseNet on the activation probability\n",
    "\n",
    "In this notebook, we test the convergence of SparseNet as a function of different learning parameters. This shows the relative robusteness of this method according to the coding parameters, but also the importance of homeostasis to obtain an efficient set of filters.\n",
    "\n",
    "See also :\n",
    "* http://blog.invibe.net/posts/2015-05-05-reproducing-olshausens-classical-sparsenet.html for a description of how SparseNet is implemented in the scikit-learn package\n",
    "* http://blog.invibe.net/posts/2015-05-06-reproducing-olshausens-classical-sparsenet-part-2.html for a descrtiption of how we managed to implement the homeostasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T22:11:05.040628Z",
     "start_time": "2018-03-18T22:11:05.008292Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T22:11:05.537652Z",
     "start_time": "2018-03-18T22:11:05.043410Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T22:11:06.012701Z",
     "start_time": "2018-03-18T22:11:05.539950Z"
    }
   },
   "outputs": [],
   "source": [
    "from shl_scripts.shl_experiments import SHL_set\n",
    "tag = 'HAP'\n",
    "experiments = SHL_set({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T22:11:06.066822Z",
     "start_time": "2018-03-18T22:11:06.021430Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data_cache/HAP.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {experiments.shl.data_cache}/{tag}.py\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "try:\n",
    "    import sys\n",
    "    command = sys.argv[1]\n",
    "except:\n",
    "    command = 'run'\n",
    "\n",
    "from shl_scripts.shl_experiments import SHL_set\n",
    "tag = 'HAP'\n",
    "#opts = dict(homeo_method=tag, eta_homeo=0.01, alpha_homeo=0.7, verbose=0)\n",
    "opts = dict(homeo_method=tag, verbose=0)\n",
    "\n",
    "n_jobs = 1\n",
    "n_jobs = 10\n",
    "n_jobs = 4\n",
    "\n",
    "experiments = SHL_set(opts, tag=tag)\n",
    "\n",
    "variables = ['eta', 'alpha_homeo']\n",
    "variables = ['eta', 'alpha_homeo', 'eta_homeo', 'l0_sparseness']\n",
    "variables = ['eta', 'alpha_homeo', 'eta_homeo']\n",
    "\n",
    "if command == 'run':\n",
    "    experiments.run(variables=variables, n_jobs=n_jobs)\n",
    "\n",
    "if command == 'plot':\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    #fig, ax = experiments.scan(variable='eta', list_figures=[], display='dynamic')\n",
    "    #fig, ax = experiments.scan(variable='eta', list_figures=[], display='final')\n",
    "    list_figures = []\n",
    "    list_figures = ['show_dico']\n",
    "    display_variables = ['error', 'logL', 'qerror', 'aerror', 'MI', 'cputime']\n",
    "    for variable in variables:\n",
    "        experiments = SHL_set(opts, tag=tag)\n",
    "        experiments.scan(variable=variable, list_figures=list_figures, display='')\n",
    "        plt.show()\n",
    "\n",
    "        for display_variable in display_variables:\n",
    "            print('Time evolution of ', display_variable)\n",
    "            fig, ax = experiments.scan(variable=variable, list_figures=[], display='dynamic', display_variable=display_variable)\n",
    "            plt.show()\n",
    "        plt.show()\n",
    "\n",
    "        for display_variable in display_variables:\n",
    "            print('Comparison at the end of learning for ', display_variable)\n",
    "            fig, ax = experiments.scan(variable=variable, list_figures=[], display='final', \n",
    "                                       label=tag, display_variable=display_variable)\n",
    "            plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T22:11:06.410089Z",
     "start_time": "2018-03-18T22:11:06.082329Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run {experiments.shl.data_cache}/{tag}.py load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T22:11:06.777881Z",
     "start_time": "2018-03-18T22:11:06.412664Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 laurentperrinet  staff  1778 Mar 18 23:11 data_cache/HAP.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l {experiments.shl.data_cache}/{tag}*\n",
    "!rm -fr {experiments.shl.data_cache}/{tag}*lock*"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T22:09:29.605078Z",
     "start_time": "2018-03-18T22:09:29.152591Z"
    }
   },
   "source": [
    "!rm -fr {experiments.shl.data_cache}/{tag}*\n",
    "!ls -l {experiments.shl.data_cache}/{tag}*\n",
    "#!rm -fr {experiments.shl.data_cache}/data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T22:11:22.776763Z",
     "start_time": "2018-03-18T22:11:06.791876Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "JoblibNameError",
     "evalue": "JoblibNameError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/laurentperrinet/science/SHL_master/probe/data_cache/HAP.py in <module>()\n     22 variables = ['eta', 'alpha_homeo']\n     23 variables = ['eta', 'alpha_homeo', 'eta_homeo', 'l0_sparseness']\n     24 variables = ['eta', 'alpha_homeo', 'eta_homeo']\n     25 \n     26 if command == 'run':\n---> 27     experiments.run(variables=variables, n_jobs=n_jobs)\n     28 \n     29 if command == 'plot':\n     30     import matplotlib.pyplot as plt\n     31 \n\n...........................................................................\n/Users/laurentperrinet/science/SHL_master/shl_scripts/shl_experiments.py in run(self=<shl_scripts.shl_experiments.SHL_set object>, N_scan=7, variables=['eta', 'alpha_homeo', 'eta_homeo'], base=4, n_jobs=4, list_figures=[], verbose=0)\n    400                 median = self.shl.__dict__[variable]\n    401                 values_[(i*N_scan):((i+1)*N_scan)] = [check_type(variable, value) for value in np.logspace(-1., 1., N_scan, base=base)*median]\n    402 \n    403             # We will use the ``joblib`` package do distribute this computation on different CPUs.\n    404             from joblib import Parallel, delayed\n--> 405             Parallel(n_jobs=n_jobs, verbose=15)(delayed(run)(variable, value, self.data, self.opts, self.matname(variable, value), list_figures) for (variable, value) in zip(variables_, values_))\n        Parallel = <class 'joblib.parallel.Parallel'>\n        n_jobs = 4\n        verbose = 0\n        value = undefined\n        self.data = array([[-0., -0., -0., ..., -0., -0., -0.],\n    ...0.],\n       [-0.,  0.,  0., ...,  0., -0., -0.]])\n        self.opts = {'homeo_method': 'HAP', 'verbose': 0}\n        self.matname = <bound method SHL_set.matname of <shl_scripts.shl_experiments.SHL_set object>>\n        list_figures = []\n        variables_ = ['eta', 'eta', 'eta', 'eta', 'eta', 'eta', 'eta', 'alpha_homeo', 'alpha_homeo', 'alpha_homeo', 'alpha_homeo', 'alpha_homeo', 'alpha_homeo', 'alpha_homeo', 'eta_homeo', 'eta_homeo', 'eta_homeo', 'eta_homeo', 'eta_homeo', 'eta_homeo', ...]\n        values_ = array([0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.01,... 3.2 , 0.01, 0.01, 0.01, 0.02, 0.03, 0.05, 0.08])\n    406 \n    407     def scan(self, N_scan=None, variable='eta', list_figures=[], base=4,\n    408                 display='', display_variable='logL',\n    409                 alpha=.6, color=None, label=None, fname=None, fig=None, ax=None, verbose=0):\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/joblib/parallel.py in __call__(self=Parallel(n_jobs=4), iterable=<generator object SHL_set.run.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=4)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nNameError                                          Sun Mar 18 23:11:21 2018\nPID: 40529                Python 3.6.4: /usr/local/opt/python/bin/python3.6\n...........................................................................\n/usr/local/lib/python3.6/site-packages/joblib/parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function run>, ('eta', 0.0005, memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), {'homeo_method': 'HAP', 'verbose': 0}, 'HAP - eta=0.00050', []), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function run>\n        args = ('eta', 0.0005, memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), {'homeo_method': 'HAP', 'verbose': 0}, 'HAP - eta=0.00050', [])\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/laurentperrinet/science/SHL_master/shl_scripts/shl_experiments.py in run(variable='eta', value=0.0005, data=memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), opts={'homeo_method': 'HAP', 'verbose': 0}, matname='HAP - eta=0.00050', list_figures=[])\n    499     # if verbose: print('DEBUG:', shl.__dict__, self.shl.__dict__)\n    500     if variable in ['patch_width']:\n    501         data = shl.get_data(**{variable:value})\n    502 \n    503     dico = shl.learn_dico(data=data, matname=matname,\n--> 504                 list_figures=list_figures)\n        list_figures = []\n    505     return shl\n    506 \n    507 if __name__ == '__main__':\n    508 \n\n...........................................................................\n/Users/laurentperrinet/science/SHL_master/shl_scripts/shl_experiments.py in learn_dico(self=<shl_scripts.shl_experiments.SHL object>, dictionary=None, precision=None, P_cum=None, data=memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), matname='HAP - eta=0.00050', record_each=None, folder_exp=None, list_figures=[], fname=None)\n    247                     try:\n    248                         if self.verbose != 0 :\n    249                             print('No cache found {}: Learning the dictionary with algo = {} \\n'.format(fmatname, self.learning_algorithm), end=' ')\n    250 \n    251                         dico = self.learn_dico(data=data, dictionary=dictionary, precision=precision, P_cum=P_cum,\n--> 252                                                matname=None)\n        matname = 'HAP - eta=0.00050'\n    253                         with open(fmatname, 'wb') as fp:\n    254                             pickle.dump(dico, fp)\n    255                     except ImportError as e:\n    256                         print('Error', e)\n\n...........................................................................\n/Users/laurentperrinet/science/SHL_master/shl_scripts/shl_experiments.py in learn_dico(self=<shl_scripts.shl_experiments.SHL object>, dictionary=None, precision=None, P_cum=None, data=memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), matname=None, record_each=None, folder_exp=None, list_figures=[], fname=None)\n    227                                          fit_tol=self.fit_tol,\n    228                                          do_precision=self.do_precision, record_each=self.record_each,\n    229 )\n    230 \n    231             if self.verbose: print('Training on %d patches' % len(data))\n--> 232             dico.fit(data)\n        dico.fit = <bound method SparseHebbianLearning.fit of <shl_scripts.shl_learn.SparseHebbianLearning object>>\n        data = memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]])\n    233 \n    234             if self.verbose:\n    235                 dt = time.time() - t0\n    236                 print('done in %.2fs.' % dt)\n\n...........................................................................\n/Users/laurentperrinet/science/SHL_master/shl_scripts/shl_learn.py in fit(self=<shl_scripts.shl_learn.SparseHebbianLearning object>, X=memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), y=None)\n    144                                   n_dictionary=self.n_dictionary,\n    145                                   l0_sparseness=self.l0_sparseness, #l0_sparseness_end=self.l0_sparseness_end,\n    146                                   n_iter=self.n_iter, method=self.fit_algorithm,\n    147                                   do_sym=self.do_sym, one_over_F=self.one_over_F,\n    148                                   batch_size=self.batch_size, record_each=self.record_each,\n--> 149                                   verbose=self.verbose\n        self.verbose = 0\n    150                                   )\n    151 \n    152         if self.record_each==0:\n    153             self.dictionary, self.precision, self.P_cum = return_fn\n\n...........................................................................\n/Users/laurentperrinet/science/SHL_master/shl_scripts/shl_learn.py in dict_learning(X=memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), dictionary=array([[-0.  , -0.02, -0.07, ..., -0.12, -0.04, ...[-0.09,  0.05, -0.03, ...,  0.07,  0.02,  0.04]]), precision=None, eta=0.0005, beta1=0.9, beta2=0.999, epsilon=1e-08, homeo_method='HAP', eta_homeo=0.02, alpha_homeo=0.8, C=2.0, nb_quant=64, P_cum=array([[0.  , 0.03, 0.05, ..., 0.97, 0.98, 1.  ]...      [0.  , 0.03, 0.05, ..., 0.97, 0.98, 1.  ]]), n_dictionary=529, l0_sparseness=29, fit_tol=None, do_precision=None, n_iter=1025, one_over_F=True, batch_size=1024, record_each=128, record_num_batches=1000, verbose=0, method='mp', do_sym=False)\n    454                                              l0_sparseness=l0_sparseness_high)\n    455 \n    456                 thr = np.percentile(sparse_code_bar.ravel(), 100 * (1 - l0_sparseness_high/n_dictionary ), axis=0)\n    457                 sparse_code_bar *= (sparse_code_bar > thr)\n    458 \n--> 459                 q = quantile(P_cum_, rescaling(sparse_code_rec, C=C), stick, do_fast=False)\n        q = array([[0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ]...      [0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ]])\n        sparse_code_rec = array([[0., 0., 0., ..., 0., 0., 0.],\n       [0...., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])\n        C = 2.0\n        stick = array([    0,    64,   128,   192,   256,   320,...33408, 33472, 33536, 33600, 33664, 33728, 33792])\n    460                 q_bar = quantile(P_cum_, rescaling(sparse_code_bar, C=C), stick, do_fast=False)\n    461                 aerror = np.mean(np.abs(q_bar-q))\n    462                 perror = 1 - np.mean( (sparse_code_bar > 0) == (sparse_code_rec>0))\n    463 \n\nNameError: name 'P_cum_' is not defined\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.6/site-packages/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/laurentperrinet/science/SHL_master/shl_scripts/shl_experiments.py\", line 504, in run\n    list_figures=list_figures)\n  File \"/Users/laurentperrinet/science/SHL_master/shl_scripts/shl_experiments.py\", line 252, in learn_dico\n    matname=None)\n  File \"/Users/laurentperrinet/science/SHL_master/shl_scripts/shl_experiments.py\", line 232, in learn_dico\n    dico.fit(data)\n  File \"/Users/laurentperrinet/science/SHL_master/shl_scripts/shl_learn.py\", line 149, in fit\n    verbose=self.verbose\n  File \"/Users/laurentperrinet/science/SHL_master/shl_scripts/shl_learn.py\", line 459, in dict_learning\n    q = quantile(P_cum_, rescaling(sparse_code_rec, C=C), stick, do_fast=False)\nNameError: name 'P_cum_' is not defined\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/Cellar/python/3.6.4_3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/local/lib/python3.6/site-packages/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\njoblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nNameError                                          Sun Mar 18 23:11:21 2018\nPID: 40529                Python 3.6.4: /usr/local/opt/python/bin/python3.6\n...........................................................................\n/usr/local/lib/python3.6/site-packages/joblib/parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function run>, ('eta', 0.0005, memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), {'homeo_method': 'HAP', 'verbose': 0}, 'HAP - eta=0.00050', []), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function run>\n        args = ('eta', 0.0005, memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), {'homeo_method': 'HAP', 'verbose': 0}, 'HAP - eta=0.00050', [])\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/laurentperrinet/science/SHL_master/shl_scripts/shl_experiments.py in run(variable='eta', value=0.0005, data=memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), opts={'homeo_method': 'HAP', 'verbose': 0}, matname='HAP - eta=0.00050', list_figures=[])\n    499     # if verbose: print('DEBUG:', shl.__dict__, self.shl.__dict__)\n    500     if variable in ['patch_width']:\n    501         data = shl.get_data(**{variable:value})\n    502 \n    503     dico = shl.learn_dico(data=data, matname=matname,\n--> 504                 list_figures=list_figures)\n        list_figures = []\n    505     return shl\n    506 \n    507 if __name__ == '__main__':\n    508 \n\n...........................................................................\n/Users/laurentperrinet/science/SHL_master/shl_scripts/shl_experiments.py in learn_dico(self=<shl_scripts.shl_experiments.SHL object>, dictionary=None, precision=None, P_cum=None, data=memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), matname='HAP - eta=0.00050', record_each=None, folder_exp=None, list_figures=[], fname=None)\n    247                     try:\n    248                         if self.verbose != 0 :\n    249                             print('No cache found {}: Learning the dictionary with algo = {} \\n'.format(fmatname, self.learning_algorithm), end=' ')\n    250 \n    251                         dico = self.learn_dico(data=data, dictionary=dictionary, precision=precision, P_cum=P_cum,\n--> 252                                                matname=None)\n        matname = 'HAP - eta=0.00050'\n    253                         with open(fmatname, 'wb') as fp:\n    254                             pickle.dump(dico, fp)\n    255                     except ImportError as e:\n    256                         print('Error', e)\n\n...........................................................................\n/Users/laurentperrinet/science/SHL_master/shl_scripts/shl_experiments.py in learn_dico(self=<shl_scripts.shl_experiments.SHL object>, dictionary=None, precision=None, P_cum=None, data=memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), matname=None, record_each=None, folder_exp=None, list_figures=[], fname=None)\n    227                                          fit_tol=self.fit_tol,\n    228                                          do_precision=self.do_precision, record_each=self.record_each,\n    229 )\n    230 \n    231             if self.verbose: print('Training on %d patches' % len(data))\n--> 232             dico.fit(data)\n        dico.fit = <bound method SparseHebbianLearning.fit of <shl_scripts.shl_learn.SparseHebbianLearning object>>\n        data = memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]])\n    233 \n    234             if self.verbose:\n    235                 dt = time.time() - t0\n    236                 print('done in %.2fs.' % dt)\n\n...........................................................................\n/Users/laurentperrinet/science/SHL_master/shl_scripts/shl_learn.py in fit(self=<shl_scripts.shl_learn.SparseHebbianLearning object>, X=memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), y=None)\n    144                                   n_dictionary=self.n_dictionary,\n    145                                   l0_sparseness=self.l0_sparseness, #l0_sparseness_end=self.l0_sparseness_end,\n    146                                   n_iter=self.n_iter, method=self.fit_algorithm,\n    147                                   do_sym=self.do_sym, one_over_F=self.one_over_F,\n    148                                   batch_size=self.batch_size, record_each=self.record_each,\n--> 149                                   verbose=self.verbose\n        self.verbose = 0\n    150                                   )\n    151 \n    152         if self.record_each==0:\n    153             self.dictionary, self.precision, self.P_cum = return_fn\n\n...........................................................................\n/Users/laurentperrinet/science/SHL_master/shl_scripts/shl_learn.py in dict_learning(X=memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), dictionary=array([[-0.  , -0.02, -0.07, ..., -0.12, -0.04, ...[-0.09,  0.05, -0.03, ...,  0.07,  0.02,  0.04]]), precision=None, eta=0.0005, beta1=0.9, beta2=0.999, epsilon=1e-08, homeo_method='HAP', eta_homeo=0.02, alpha_homeo=0.8, C=2.0, nb_quant=64, P_cum=array([[0.  , 0.03, 0.05, ..., 0.97, 0.98, 1.  ]...      [0.  , 0.03, 0.05, ..., 0.97, 0.98, 1.  ]]), n_dictionary=529, l0_sparseness=29, fit_tol=None, do_precision=None, n_iter=1025, one_over_F=True, batch_size=1024, record_each=128, record_num_batches=1000, verbose=0, method='mp', do_sym=False)\n    454                                              l0_sparseness=l0_sparseness_high)\n    455 \n    456                 thr = np.percentile(sparse_code_bar.ravel(), 100 * (1 - l0_sparseness_high/n_dictionary ), axis=0)\n    457                 sparse_code_bar *= (sparse_code_bar > thr)\n    458 \n--> 459                 q = quantile(P_cum_, rescaling(sparse_code_rec, C=C), stick, do_fast=False)\n        q = array([[0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ]...      [0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ]])\n        sparse_code_rec = array([[0., 0., 0., ..., 0., 0., 0.],\n       [0...., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])\n        C = 2.0\n        stick = array([    0,    64,   128,   192,   256,   320,...33408, 33472, 33536, 33600, 33664, 33728, 33792])\n    460                 q_bar = quantile(P_cum_, rescaling(sparse_code_bar, C=C), stick, do_fast=False)\n    461                 aerror = np.mean(np.abs(q_bar-q))\n    462                 perror = 1 - np.mean( (sparse_code_bar > 0) == (sparse_code_rec>0))\n    463 \n\nNameError: name 'P_cum_' is not defined\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.4_3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nNameError                                          Sun Mar 18 23:11:21 2018\nPID: 40529                Python 3.6.4: /usr/local/opt/python/bin/python3.6\n...........................................................................\n/usr/local/lib/python3.6/site-packages/joblib/parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function run>, ('eta', 0.0005, memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), {'homeo_method': 'HAP', 'verbose': 0}, 'HAP - eta=0.00050', []), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function run>\n        args = ('eta', 0.0005, memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), {'homeo_method': 'HAP', 'verbose': 0}, 'HAP - eta=0.00050', [])\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/laurentperrinet/science/SHL_master/shl_scripts/shl_experiments.py in run(variable='eta', value=0.0005, data=memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), opts={'homeo_method': 'HAP', 'verbose': 0}, matname='HAP - eta=0.00050', list_figures=[])\n    499     # if verbose: print('DEBUG:', shl.__dict__, self.shl.__dict__)\n    500     if variable in ['patch_width']:\n    501         data = shl.get_data(**{variable:value})\n    502 \n    503     dico = shl.learn_dico(data=data, matname=matname,\n--> 504                 list_figures=list_figures)\n        list_figures = []\n    505     return shl\n    506 \n    507 if __name__ == '__main__':\n    508 \n\n...........................................................................\n/Users/laurentperrinet/science/SHL_master/shl_scripts/shl_experiments.py in learn_dico(self=<shl_scripts.shl_experiments.SHL object>, dictionary=None, precision=None, P_cum=None, data=memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), matname='HAP - eta=0.00050', record_each=None, folder_exp=None, list_figures=[], fname=None)\n    247                     try:\n    248                         if self.verbose != 0 :\n    249                             print('No cache found {}: Learning the dictionary with algo = {} \\n'.format(fmatname, self.learning_algorithm), end=' ')\n    250 \n    251                         dico = self.learn_dico(data=data, dictionary=dictionary, precision=precision, P_cum=P_cum,\n--> 252                                                matname=None)\n        matname = 'HAP - eta=0.00050'\n    253                         with open(fmatname, 'wb') as fp:\n    254                             pickle.dump(dico, fp)\n    255                     except ImportError as e:\n    256                         print('Error', e)\n\n...........................................................................\n/Users/laurentperrinet/science/SHL_master/shl_scripts/shl_experiments.py in learn_dico(self=<shl_scripts.shl_experiments.SHL object>, dictionary=None, precision=None, P_cum=None, data=memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), matname=None, record_each=None, folder_exp=None, list_figures=[], fname=None)\n    227                                          fit_tol=self.fit_tol,\n    228                                          do_precision=self.do_precision, record_each=self.record_each,\n    229 )\n    230 \n    231             if self.verbose: print('Training on %d patches' % len(data))\n--> 232             dico.fit(data)\n        dico.fit = <bound method SparseHebbianLearning.fit of <shl_scripts.shl_learn.SparseHebbianLearning object>>\n        data = memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]])\n    233 \n    234             if self.verbose:\n    235                 dt = time.time() - t0\n    236                 print('done in %.2fs.' % dt)\n\n...........................................................................\n/Users/laurentperrinet/science/SHL_master/shl_scripts/shl_learn.py in fit(self=<shl_scripts.shl_learn.SparseHebbianLearning object>, X=memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), y=None)\n    144                                   n_dictionary=self.n_dictionary,\n    145                                   l0_sparseness=self.l0_sparseness, #l0_sparseness_end=self.l0_sparseness_end,\n    146                                   n_iter=self.n_iter, method=self.fit_algorithm,\n    147                                   do_sym=self.do_sym, one_over_F=self.one_over_F,\n    148                                   batch_size=self.batch_size, record_each=self.record_each,\n--> 149                                   verbose=self.verbose\n        self.verbose = 0\n    150                                   )\n    151 \n    152         if self.record_each==0:\n    153             self.dictionary, self.precision, self.P_cum = return_fn\n\n...........................................................................\n/Users/laurentperrinet/science/SHL_master/shl_scripts/shl_learn.py in dict_learning(X=memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), dictionary=array([[-0.  , -0.02, -0.07, ..., -0.12, -0.04, ...[-0.09,  0.05, -0.03, ...,  0.07,  0.02,  0.04]]), precision=None, eta=0.0005, beta1=0.9, beta2=0.999, epsilon=1e-08, homeo_method='HAP', eta_homeo=0.02, alpha_homeo=0.8, C=2.0, nb_quant=64, P_cum=array([[0.  , 0.03, 0.05, ..., 0.97, 0.98, 1.  ]...      [0.  , 0.03, 0.05, ..., 0.97, 0.98, 1.  ]]), n_dictionary=529, l0_sparseness=29, fit_tol=None, do_precision=None, n_iter=1025, one_over_F=True, batch_size=1024, record_each=128, record_num_batches=1000, verbose=0, method='mp', do_sym=False)\n    454                                              l0_sparseness=l0_sparseness_high)\n    455 \n    456                 thr = np.percentile(sparse_code_bar.ravel(), 100 * (1 - l0_sparseness_high/n_dictionary ), axis=0)\n    457                 sparse_code_bar *= (sparse_code_bar > thr)\n    458 \n--> 459                 q = quantile(P_cum_, rescaling(sparse_code_rec, C=C), stick, do_fast=False)\n        q = array([[0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ]...      [0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ]])\n        sparse_code_rec = array([[0., 0., 0., ..., 0., 0., 0.],\n       [0...., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])\n        C = 2.0\n        stick = array([    0,    64,   128,   192,   256,   320,...33408, 33472, 33536, 33600, 33664, 33728, 33792])\n    460                 q_bar = quantile(P_cum_, rescaling(sparse_code_bar, C=C), stick, do_fast=False)\n    461                 aerror = np.mean(np.abs(q_bar-q))\n    462                 perror = 1 - np.mean( (sparse_code_bar > 0) == (sparse_code_rec>0))\n    463 \n\nNameError: name 'P_cum_' is not defined\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibNameError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/science/SHL_master/probe/data_cache/HAP.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'run'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mexperiments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/science/SHL_master/shl_scripts/shl_experiments.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N_scan, variables, base, n_jobs, list_figures, verbose)\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;31m# We will use the ``joblib`` package do distribute this computation on different CPUs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m             \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_figures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     def scan(self, N_scan=None, variable='eta', list_figures=[], base=4,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibNameError\u001b[0m: JoblibNameError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/laurentperrinet/science/SHL_master/probe/data_cache/HAP.py in <module>()\n     22 variables = ['eta', 'alpha_homeo']\n     23 variables = ['eta', 'alpha_homeo', 'eta_homeo', 'l0_sparseness']\n     24 variables = ['eta', 'alpha_homeo', 'eta_homeo']\n     25 \n     26 if command == 'run':\n---> 27     experiments.run(variables=variables, n_jobs=n_jobs)\n     28 \n     29 if command == 'plot':\n     30     import matplotlib.pyplot as plt\n     31 \n\n...........................................................................\n/Users/laurentperrinet/science/SHL_master/shl_scripts/shl_experiments.py in run(self=<shl_scripts.shl_experiments.SHL_set object>, N_scan=7, variables=['eta', 'alpha_homeo', 'eta_homeo'], base=4, n_jobs=4, list_figures=[], verbose=0)\n    400                 median = self.shl.__dict__[variable]\n    401                 values_[(i*N_scan):((i+1)*N_scan)] = [check_type(variable, value) for value in np.logspace(-1., 1., N_scan, base=base)*median]\n    402 \n    403             # We will use the ``joblib`` package do distribute this computation on different CPUs.\n    404             from joblib import Parallel, delayed\n--> 405             Parallel(n_jobs=n_jobs, verbose=15)(delayed(run)(variable, value, self.data, self.opts, self.matname(variable, value), list_figures) for (variable, value) in zip(variables_, values_))\n        Parallel = <class 'joblib.parallel.Parallel'>\n        n_jobs = 4\n        verbose = 0\n        value = undefined\n        self.data = array([[-0., -0., -0., ..., -0., -0., -0.],\n    ...0.],\n       [-0.,  0.,  0., ...,  0., -0., -0.]])\n        self.opts = {'homeo_method': 'HAP', 'verbose': 0}\n        self.matname = <bound method SHL_set.matname of <shl_scripts.shl_experiments.SHL_set object>>\n        list_figures = []\n        variables_ = ['eta', 'eta', 'eta', 'eta', 'eta', 'eta', 'eta', 'alpha_homeo', 'alpha_homeo', 'alpha_homeo', 'alpha_homeo', 'alpha_homeo', 'alpha_homeo', 'alpha_homeo', 'eta_homeo', 'eta_homeo', 'eta_homeo', 'eta_homeo', 'eta_homeo', 'eta_homeo', ...]\n        values_ = array([0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.01,... 3.2 , 0.01, 0.01, 0.01, 0.02, 0.03, 0.05, 0.08])\n    406 \n    407     def scan(self, N_scan=None, variable='eta', list_figures=[], base=4,\n    408                 display='', display_variable='logL',\n    409                 alpha=.6, color=None, label=None, fname=None, fig=None, ax=None, verbose=0):\n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/joblib/parallel.py in __call__(self=Parallel(n_jobs=4), iterable=<generator object SHL_set.run.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=4)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nNameError                                          Sun Mar 18 23:11:21 2018\nPID: 40529                Python 3.6.4: /usr/local/opt/python/bin/python3.6\n...........................................................................\n/usr/local/lib/python3.6/site-packages/joblib/parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function run>, ('eta', 0.0005, memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), {'homeo_method': 'HAP', 'verbose': 0}, 'HAP - eta=0.00050', []), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/site-packages/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function run>\n        args = ('eta', 0.0005, memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), {'homeo_method': 'HAP', 'verbose': 0}, 'HAP - eta=0.00050', [])\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/laurentperrinet/science/SHL_master/shl_scripts/shl_experiments.py in run(variable='eta', value=0.0005, data=memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), opts={'homeo_method': 'HAP', 'verbose': 0}, matname='HAP - eta=0.00050', list_figures=[])\n    499     # if verbose: print('DEBUG:', shl.__dict__, self.shl.__dict__)\n    500     if variable in ['patch_width']:\n    501         data = shl.get_data(**{variable:value})\n    502 \n    503     dico = shl.learn_dico(data=data, matname=matname,\n--> 504                 list_figures=list_figures)\n        list_figures = []\n    505     return shl\n    506 \n    507 if __name__ == '__main__':\n    508 \n\n...........................................................................\n/Users/laurentperrinet/science/SHL_master/shl_scripts/shl_experiments.py in learn_dico(self=<shl_scripts.shl_experiments.SHL object>, dictionary=None, precision=None, P_cum=None, data=memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), matname='HAP - eta=0.00050', record_each=None, folder_exp=None, list_figures=[], fname=None)\n    247                     try:\n    248                         if self.verbose != 0 :\n    249                             print('No cache found {}: Learning the dictionary with algo = {} \\n'.format(fmatname, self.learning_algorithm), end=' ')\n    250 \n    251                         dico = self.learn_dico(data=data, dictionary=dictionary, precision=precision, P_cum=P_cum,\n--> 252                                                matname=None)\n        matname = 'HAP - eta=0.00050'\n    253                         with open(fmatname, 'wb') as fp:\n    254                             pickle.dump(dico, fp)\n    255                     except ImportError as e:\n    256                         print('Error', e)\n\n...........................................................................\n/Users/laurentperrinet/science/SHL_master/shl_scripts/shl_experiments.py in learn_dico(self=<shl_scripts.shl_experiments.SHL object>, dictionary=None, precision=None, P_cum=None, data=memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), matname=None, record_each=None, folder_exp=None, list_figures=[], fname=None)\n    227                                          fit_tol=self.fit_tol,\n    228                                          do_precision=self.do_precision, record_each=self.record_each,\n    229 )\n    230 \n    231             if self.verbose: print('Training on %d patches' % len(data))\n--> 232             dico.fit(data)\n        dico.fit = <bound method SparseHebbianLearning.fit of <shl_scripts.shl_learn.SparseHebbianLearning object>>\n        data = memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]])\n    233 \n    234             if self.verbose:\n    235                 dt = time.time() - t0\n    236                 print('done in %.2fs.' % dt)\n\n...........................................................................\n/Users/laurentperrinet/science/SHL_master/shl_scripts/shl_learn.py in fit(self=<shl_scripts.shl_learn.SparseHebbianLearning object>, X=memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), y=None)\n    144                                   n_dictionary=self.n_dictionary,\n    145                                   l0_sparseness=self.l0_sparseness, #l0_sparseness_end=self.l0_sparseness_end,\n    146                                   n_iter=self.n_iter, method=self.fit_algorithm,\n    147                                   do_sym=self.do_sym, one_over_F=self.one_over_F,\n    148                                   batch_size=self.batch_size, record_each=self.record_each,\n--> 149                                   verbose=self.verbose\n        self.verbose = 0\n    150                                   )\n    151 \n    152         if self.record_each==0:\n    153             self.dictionary, self.precision, self.P_cum = return_fn\n\n...........................................................................\n/Users/laurentperrinet/science/SHL_master/shl_scripts/shl_learn.py in dict_learning(X=memmap([[-0., -0., -0., ..., -0., -0., -0.],\n   ....],\n        [-0.,  0.,  0., ...,  0., -0., -0.]]), dictionary=array([[-0.  , -0.02, -0.07, ..., -0.12, -0.04, ...[-0.09,  0.05, -0.03, ...,  0.07,  0.02,  0.04]]), precision=None, eta=0.0005, beta1=0.9, beta2=0.999, epsilon=1e-08, homeo_method='HAP', eta_homeo=0.02, alpha_homeo=0.8, C=2.0, nb_quant=64, P_cum=array([[0.  , 0.03, 0.05, ..., 0.97, 0.98, 1.  ]...      [0.  , 0.03, 0.05, ..., 0.97, 0.98, 1.  ]]), n_dictionary=529, l0_sparseness=29, fit_tol=None, do_precision=None, n_iter=1025, one_over_F=True, batch_size=1024, record_each=128, record_num_batches=1000, verbose=0, method='mp', do_sym=False)\n    454                                              l0_sparseness=l0_sparseness_high)\n    455 \n    456                 thr = np.percentile(sparse_code_bar.ravel(), 100 * (1 - l0_sparseness_high/n_dictionary ), axis=0)\n    457                 sparse_code_bar *= (sparse_code_bar > thr)\n    458 \n--> 459                 q = quantile(P_cum_, rescaling(sparse_code_rec, C=C), stick, do_fast=False)\n        q = array([[0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ]...      [0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  ]])\n        sparse_code_rec = array([[0., 0., 0., ..., 0., 0., 0.],\n       [0...., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])\n        C = 2.0\n        stick = array([    0,    64,   128,   192,   256,   320,...33408, 33472, 33536, 33600, 33664, 33728, 33792])\n    460                 q_bar = quantile(P_cum_, rescaling(sparse_code_bar, C=C), stick, do_fast=False)\n    461                 aerror = np.mean(np.abs(q_bar-q))\n    462                 perror = 1 - np.mean( (sparse_code_bar > 0) == (sparse_code_rec>0))\n    463 \n\nNameError: name 'P_cum_' is not defined\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "%run {experiments.shl.data_cache}/{tag}.py run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T22:11:25.962084Z",
     "start_time": "2018-03-18T22:11:22.780929Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'P_cum_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/science/SHL_master/probe/data_cache/HAP.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvariable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mexperiments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSHL_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mexperiments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_figures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist_figures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/science/SHL_master/shl_scripts/shl_experiments.py\u001b[0m in \u001b[0;36mscan\u001b[0;34m(self, N_scan, variable, list_figures, base, display, display_variable, alpha, color, label, fname, fig, ax, verbose)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheck_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_scan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_scan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DEBUG:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmedian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/science/SHL_master/shl_scripts/shl_experiments.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N_scan, variables, base, n_jobs, list_figures, verbose)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheck_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m                     \u001b[0mshl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_figures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m                     dico = shl.learn_dico(data=self.data, matname=self.matname(variable, value),\n\u001b[1;32m    395\u001b[0m                                 list_figures=list_figures)\n",
      "\u001b[0;32m~/science/SHL_master/shl_scripts/shl_experiments.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(variable, value, data, opts, matname, list_figures)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     dico = shl.learn_dico(data=data, matname=matname,\n\u001b[0;32m--> 504\u001b[0;31m                 list_figures=list_figures)\n\u001b[0m\u001b[1;32m    505\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mshl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/science/SHL_master/shl_scripts/shl_experiments.py\u001b[0m in \u001b[0;36mlearn_dico\u001b[0;34m(self, dictionary, precision, P_cum, data, matname, record_each, folder_exp, list_figures, fname)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                         dico = self.learn_dico(data=data, dictionary=dictionary, precision=precision, P_cum=P_cum,\n\u001b[0;32m--> 252\u001b[0;31m                                                matname=None)\n\u001b[0m\u001b[1;32m    253\u001b[0m                         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmatname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                             \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdico\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/science/SHL_master/shl_scripts/shl_experiments.py\u001b[0m in \u001b[0;36mlearn_dico\u001b[0;34m(self, dictionary, precision, P_cum, data, matname, record_each, folder_exp, list_figures, fname)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training on %d patches'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0mdico\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/science/SHL_master/shl_scripts/shl_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    147\u001b[0m                                   \u001b[0mdo_sym\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_sym\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_over_F\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_over_F\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                                   \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_each\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_each\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                                   \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m                                   )\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/science/SHL_master/shl_scripts/shl_learn.py\u001b[0m in \u001b[0;36mdict_learning\u001b[0;34m(X, dictionary, precision, eta, beta1, beta2, epsilon, homeo_method, eta_homeo, alpha_homeo, C, nb_quant, P_cum, n_dictionary, l0_sparseness, fit_tol, do_precision, n_iter, one_over_F, batch_size, record_each, record_num_batches, verbose, method, do_sym)\u001b[0m\n\u001b[1;32m    457\u001b[0m                 \u001b[0msparse_code_bar\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msparse_code_bar\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m                 \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP_cum_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrescaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_code_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstick\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_fast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m                 \u001b[0mq_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP_cum_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrescaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_code_bar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstick\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_fast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m                 \u001b[0maerror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_bar\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'P_cum_' is not defined"
     ]
    }
   ],
   "source": [
    "%run {experiments.shl.data_cache}/{tag}.py plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T22:11:26.022605Z",
     "start_time": "2018-03-18T22:11:25.965601Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "Software versions": [
        {
         "module": "Python",
         "version": "3.6.4 64bit [GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.39.2)]"
        },
        {
         "module": "IPython",
         "version": "6.2.1"
        },
        {
         "module": "OS",
         "version": "Darwin 17.4.0 x86_64 i386 64bit"
        },
        {
         "module": "numpy",
         "version": "1.14.1"
        },
        {
         "module": "shl_scripts",
         "version": "20171221"
        },
        {
         "module": "pandas",
         "version": "0.22.0"
        }
       ]
      },
      "text/html": [
       "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.6.4 64bit [GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.39.2)]</td></tr><tr><td>IPython</td><td>6.2.1</td></tr><tr><td>OS</td><td>Darwin 17.4.0 x86_64 i386 64bit</td></tr><tr><td>numpy</td><td>1.14.1</td></tr><tr><td>shl_scripts</td><td>20171221</td></tr><tr><td>pandas</td><td>0.22.0</td></tr><tr><td colspan='2'>Sun Mar 18 23:11:26 2018 CET</td></tr></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{|l|l|}\\hline\n",
       "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
       "Python & 3.6.4 64bit [GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.39.2)] \\\\ \\hline\n",
       "IPython & 6.2.1 \\\\ \\hline\n",
       "OS & Darwin 17.4.0 x86\\_64 i386 64bit \\\\ \\hline\n",
       "numpy & 1.14.1 \\\\ \\hline\n",
       "shl_scripts & 20171221 \\\\ \\hline\n",
       "pandas & 0.22.0 \\\\ \\hline\n",
       "\\hline \\multicolumn{2}{|l|}{Sun Mar 18 23:11:26 2018 CET} \\\\ \\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Software versions\n",
       "Python 3.6.4 64bit [GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.39.2)]\n",
       "IPython 6.2.1\n",
       "OS Darwin 17.4.0 x86_64 i386 64bit\n",
       "numpy 1.14.1\n",
       "shl_scripts 20171221\n",
       "pandas 0.22.0\n",
       "Sun Mar 18 23:11:26 2018 CET"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext version_information\n",
    "%version_information numpy, shl_scripts, pandas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {
    "height": "99px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
