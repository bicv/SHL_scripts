{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Hebbian Learning with full homeostasis : testing different rescaling functions\n",
    "\n",
    "In this notebook, we test the convergence of SparseNet as a function of different parameters tuning the quantization. These parameters only influence the way we select dictionary elements and thus the homeostasis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T16:51:33.870539Z",
     "start_time": "2018-01-10T16:51:33.071615Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T16:51:34.224931Z",
     "start_time": "2018-01-10T16:51:33.874121Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from shl_scripts.shl_experiments import SHL\n",
    "\n",
    "list_figures = ['show_dico']#, 'plot_variance',  'plot_variance_histogram',  'time_plot_prob',  'time_plot_kurt',  'time_plot_var']\n",
    "DEBUG_DOWNSCALE, verbose = 10, 0\n",
    "DEBUG_DOWNSCALE, verbose = 10, 100\n",
    "DEBUG_DOWNSCALE, verbose = 1, 0\n",
    "tag = 'rescaling'\n",
    "\n",
    "N_scan = 7\n",
    "n_jobs = 1\n",
    "opts = dict(DEBUG_DOWNSCALE=DEBUG_DOWNSCALE, homeo_method='HEH', homeo_params=dict(eta_homeo=0.05, alpha_homeo=0.02, C=5., nb_quant=128), verbose=verbose)\n",
    "shl = SHL(**opts)\n",
    "data = shl.get_data(matname='data')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import time\n",
    "time.sleep(3600*15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T16:51:34.402903Z",
     "start_time": "2018-01-10T16:51:34.248877Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls -l data_cache/{tag}*"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!rm -fr data_cache/{tag}*"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!ls -l data_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T16:51:34.420911Z",
     "start_time": "2018-01-10T16:51:34.407144Z"
    }
   },
   "outputs": [],
   "source": [
    "homeo_params = shl.homeo_params\n",
    "homeo_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the ``joblib`` package do distribute this computation on different CPUs."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from joblib import Parallel, delayed\n",
    "Parallel(n_jobs=n_jobs)(delayed(np.sqrt)(i ** 2) for i in range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## different rescaling values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def run(C, list_figures, data, homeo_params):\n",
    "    matname = tag + ' - C={}'.format(C)\n",
    "    shl = SHL(**opts, homeo_params=homeo_params.update(C=C))\n",
    "    dico = shl.learn_dico(data=data, matname=matname, list_figures=list_figures)\n",
    "    return dico\n",
    "\n",
    "\n",
    "Cs = np.linspace(0, 10, 5)\n",
    "if not n_jobs==1: out = Parallel(n_jobs=n_jobs, verbose=15)(delayed(run)(C, [], data, homeo_params) for C in Cs)\n",
    "\n",
    "for C in Cs:\n",
    "    dico = run(C, list_figures=list_figures, data=data, homeo_params=homeo_params)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## different quantization parameters"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "2 ** np.arange(3, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with a fixed $C=5.$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "from joblib import Parallel, delayed\n",
    "def run(nb_quant, list_figures, data, homeo_params=homeo_params):\n",
    "    matname = tag + ' - nb_quant={}'.format(nb_quant)\n",
    "    shl = SHL(**opts, homeo_params=homeo_params.update(C=5., nb_quant=nb_quant))\n",
    "    dico = shl.learn_dico(data=data, matname=matname, list_figures=list_figures)\n",
    "    return dico\n",
    "\n",
    "nb_quants = 2 ** np.arange(3, 9)\n",
    "if not n_jobs==1: out = Parallel(n_jobs=n_jobs, verbose=15)(delayed(run)(int(nb_quant), [], data, homeo_params) for nb_quant in  nb_quants)\n",
    "\n",
    "for nb_quant in  nb_quants:\n",
    "    dico = run(nb_quant, list_figures=list_figures, data=data, homeo_params=homeo_params)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T16:51:34.431795Z",
     "start_time": "2018-01-10T16:51:34.424382Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shl = SHL(**opts)\n",
    "homeo_params = shl.homeo_params\n",
    "homeo_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T16:51:34.441892Z",
     "start_time": "2018-01-10T16:51:34.434408Z"
    }
   },
   "outputs": [],
   "source": [
    "print(homeo_params.update(eta_homeo=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T16:55:37.740553Z",
     "start_time": "2018-01-10T16:51:34.444909Z"
    }
   },
   "outputs": [],
   "source": [
    "shl = SHL(**opts)\n",
    "for eta_homeo in np.logspace(-1, 1, N_scan, base=10)*shl.homeo_params['eta_homeo']:\n",
    "    matname = tag + ' - eta_homeo={eta_homeo}'.format(eta_homeo=eta_homeo)\n",
    "    homeo_params=shl.homeo_params\n",
    "    homeo_params.update(eta_homeo=eta_homeo)\n",
    "    opts.update(homeo_params=homeo_params)\n",
    "    shl = SHL(**opts)\n",
    "    dico = shl.learn_dico(data=data, matname=matname, list_figures=list_figures)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T16:57:45.567948Z",
     "start_time": "2018-01-10T16:55:37.743307Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nb_quants = 2 ** np.arange(3, 9)\n",
    "opts_ = opts.copy()\n",
    "for nb_quant in  nb_quants:\n",
    "    matname = tag + ' - nb_quant={}'.format(nb_quant)\n",
    "    homeo_params = shl.homeo_params\n",
    "    homeo_params.update(C=5.)\n",
    "    homeo_params.update(nb_quant=nb_quant)\n",
    "    opts.update(homeo_params=homeo_params)\n",
    "    shl = SHL(**opts)\n",
    "    dico = shl.learn_dico(data=data, matname=matname, list_figures=list_figures)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with an adaptive rescaling function ($C=0.$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T17:00:37.210706Z",
     "start_time": "2018-01-10T16:57:45.570434Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shl = SHL(**opts)\n",
    "opts_ = opts.copy()\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "def run(shl, nb_quant, list_figures, data):\n",
    "    matname = tag + ' - auto - nb_quant={}'.format(nb_quant)\n",
    "    homeo_params = shl.homeo_params\n",
    "    homeo_params.update(C=0.)\n",
    "    homeo_params.update(nb_quant=nb_quant)\n",
    "    opts_.update(homeo_params=homeo_params)\n",
    "    shl = SHL(**opts_)\n",
    "    dico = shl.learn_dico(data=data, matname=matname, list_figures=list_figures)\n",
    "    return dico\n",
    "\n",
    "nb_quants = 2 ** np.arange(3, 9)\n",
    "if not n_jobs==1: out = Parallel(n_jobs=n_jobs, verbose=15)(delayed(run)(shl, int(nb_quant), [], data) for nb_quant in  nb_quants)\n",
    "\n",
    "for nb_quant in  nb_quants:\n",
    "    dico = run(shl, nb_quant, list_figures, data)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T17:00:37.212045Z",
     "start_time": "2018-01-10T16:51:33.322Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext version_information\n",
    "%version_information numpy, shl_scripts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {
    "height": "81px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
