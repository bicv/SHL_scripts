{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homeostasis Ã -la-SparseNet on the activation probability\n",
    "\n",
    "In this notebook, we test the convergence of SparseNet as a function of different learning parameters. This shows the relative robusteness of this method according to the coding parameters, but also the importance of homeostasis to obtain an efficient set of filters.\n",
    "\n",
    "See also :\n",
    "* http://blog.invibe.net/posts/2015-05-05-reproducing-olshausens-classical-sparsenet.html for a description of how SparseNet is implemented in the scikit-learn package\n",
    "* http://blog.invibe.net/posts/2015-05-06-reproducing-olshausens-classical-sparsenet-part-2.html for a descrtiption of how we managed to implement the homeostasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T08:03:15.327261Z",
     "start_time": "2018-09-26T08:03:15.308114Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T08:03:15.827617Z",
     "start_time": "2018-09-26T08:03:15.329663Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T08:03:16.065583Z",
     "start_time": "2018-09-26T08:03:15.829623Z"
    }
   },
   "outputs": [],
   "source": [
    "from shl_scripts.shl_experiments import SHL_set\n",
    "tag = 'nohomeo'\n",
    "opts = dict(homeo_method='None', verbose=0)\n",
    "experiments = SHL_set(opts, tag=tag)\n",
    "\n",
    "list_figures = []\n",
    "list_figures = ['show_dico']\n",
    "\n",
    "\n",
    "display_variables = ['error', 'logL', 'cputime']\n",
    "display_variables = ['error', 'logL', 'perror', 'MC', 'cputime']\n",
    "display_variables = ['F']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T08:03:16.350401Z",
     "start_time": "2018-09-26T08:03:16.068659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 lolo  staff  2194267 Sep 17 11:11 cache_dir/nohomeo - algorithm=lasso_lars - eta=0.00500_dico.pkl\r\n",
      "-rw-r--r--  1 lolo  staff  2194259 Sep 17 11:08 cache_dir/nohomeo - eta=0.00500_dico.pkl\r\n",
      "-rw-r--r--  1 lolo  staff  4620187 Sep 15 00:05 cache_dir/nohomeo - eta=0.01000_dico.pkl\r\n",
      "-rw-r--r--  1 lolo  staff  4620187 Sep 15 06:11 cache_dir/nohomeo - eta=0.01414_dico.pkl\r\n",
      "-rw-r--r--  1 lolo  staff  4620187 Sep 15 11:37 cache_dir/nohomeo - eta=0.02000_dico.pkl\r\n",
      "-rw-r--r--  1 lolo  staff  4620187 Sep 15 16:02 cache_dir/nohomeo - eta=0.02828_dico.pkl\r\n",
      "-rw-r--r--  1 lolo  staff  4620187 Sep 15 18:22 cache_dir/nohomeo - eta=0.04000_dico.pkl\r\n",
      "-rw-r--r--  1 lolo  staff  4620187 Sep 15 22:41 cache_dir/nohomeo - eta=0.05657_dico.pkl\r\n",
      "-rw-r--r--  1 lolo  staff  4620187 Sep 16 04:04 cache_dir/nohomeo - eta=0.08000_dico.pkl\r\n",
      "-rw-r--r--  1 lolo  staff  4620187 Sep 16 09:29 cache_dir/nohomeo - eta=0.11314_dico.pkl\r\n",
      "-rw-r--r--  1 lolo  staff  4620187 Sep 16 14:28 cache_dir/nohomeo - eta=0.16000_dico.pkl\r\n",
      "-rw-r--r--  1 lolo  staff  5768112 Sep 17 00:03 cache_dir/nohomeo - n_iter=11586_dico.pkl\r\n",
      "-rw-r--r--  1 lolo  staff  7392612 Sep 17 02:58 cache_dir/nohomeo - n_iter=16386_dico.pkl\r\n",
      "-rw-r--r--  1 lolo  staff  2529935 Sep 16 15:30 cache_dir/nohomeo - n_iter=2048_dico.pkl\r\n",
      "-rw-r--r--  1 lolo  staff  9688572 Sep 17 08:24 cache_dir/nohomeo - n_iter=23173_dico.pkl\r\n",
      "-rw-r--r--  1 lolo  staff  2822345 Sep 16 16:32 cache_dir/nohomeo - n_iter=2896_dico.pkl\r\n",
      "-rw-r--r--  1 lolo  staff  3223055 Sep 16 17:43 cache_dir/nohomeo - n_iter=4096_dico.pkl\r\n",
      "-rw-r--r--  1 lolo  staff  3807875 Sep 16 19:23 cache_dir/nohomeo - n_iter=5793_dico.pkl\r\n",
      "-rw-r--r--  1 lolo  staff  4620132 Sep 16 21:32 cache_dir/nohomeo - n_iter=8193_dico.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l {experiments.shl.cache_dir}/{tag}*\n",
    "!rm -fr {experiments.shl.cache_dir}/{tag}*lock*"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!rm -fr {experiments.shl.cache_dir}/{tag}*\n",
    "#!rm -fr cache_dir/data_data.npy\n",
    "!ls -l {experiments.shl.cache_dir}/{tag}*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With different learning rates but without homeostasis\n",
    "\n",
    "Here,we only ensure the norm ofthe filters is constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T08:31:43.580799Z",
     "start_time": "2018-09-26T08:03:16.353621Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c1ca9a9d085e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexperiments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'eta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_figures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist_figures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdisplay_variable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdisplay_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'eta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_figures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dynamic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_variable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplay_variable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tmp/SparseHebbianLearning/shl_scripts/shl_experiments.py\u001b[0m in \u001b[0;36mscan\u001b[0;34m(self, N_scan, variable, list_figures, display, display_variable, alpha, color, label, fname, fig, ax, fig_kwargs, verbose)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_figures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfig_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m     def scan(self, N_scan=None, variable='eta', list_figures=[],\n\u001b[0m\u001b[1;32m    436\u001b[0m                 \u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_variable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'logL'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tmp/SparseHebbianLearning/shl_scripts/shl_experiments.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N_scan, variables, n_jobs, list_figures, fig_kwargs, verbose)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mvariables_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_scan\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m             \u001b[0mvariables_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mN_scan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_scan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0mvalues_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mN_scan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mN_scan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tmp/SparseHebbianLearning/shl_scripts/shl_experiments.py\u001b[0m in \u001b[0;36mprun\u001b[0;34m(variable, value, data, opts, matname, list_figures, fig_kwargs, verbose)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running variable'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'with value'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0mshl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSHL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0mshl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tmp/SparseHebbianLearning/shl_scripts/shl_experiments.py\u001b[0m in \u001b[0;36mlearn_dico\u001b[0;34m(self, dictionary, precision, P_cum, data, matname, record_each, folder_exp, list_figures, fig_kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No cache found {}: Learning the dictionary with algo = {} \\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmatname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_algorithm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m                         dico = self.learn_dico(data=data, dictionary=dictionary, precision=precision, P_cum=P_cum,\n\u001b[1;32m    261\u001b[0m                                                matname=None)\n",
      "\u001b[0;32m~/tmp/SparseHebbianLearning/shl_scripts/shl_experiments.py\u001b[0m in \u001b[0;36mlearn_dico\u001b[0;34m(self, dictionary, precision, P_cum, data, matname, record_each, folder_exp, list_figures, fig_kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m                                          \u001b[0mrecord_num_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_num_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m )\n\u001b[0;32m--> 239\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training on %d patches'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mdico\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tmp/SparseHebbianLearning/shl_scripts/shl_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    152\u001b[0m                                   \u001b[0mdo_sym\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_sym\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_over_F\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_over_F\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                                   \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                                   \u001b[0mrecord_each\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_each\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m                                   \u001b[0mrecord_num_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_num_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                                   \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tmp/SparseHebbianLearning/shl_scripts/shl_learn.py\u001b[0m in \u001b[0;36mdict_learning\u001b[0;34m(X, dictionary, precision, eta, beta1, beta2, epsilon, homeo_method, eta_homeo, alpha_homeo, C, nb_quant, P_cum, n_dictionary, l0_sparseness, fit_tol, alpha_MP, do_precision, n_iter, one_over_F, batch_size, record_each, record_num_batches, verbose, method, do_sym)\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;31m# homeostasis : we compute P_cum and define different strategies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         mean_measure, P_cum, gain = homeostasis(mean_measure, P_cum, gain,\n\u001b[0;32m--> 414\u001b[0;31m                         \u001b[0mhomeo_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta_homeo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_homeo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m                         nb_quant=nb_quant, verbose=verbose, C=C, do_sym=do_sym)\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tmp/SparseHebbianLearning/shl_scripts/shl_learn.py\u001b[0m in \u001b[0;36mhomeostasis\u001b[0;34m(mean_measure, P_cum, gain, homeo_method, sparse_code, eta_homeo, alpha_homeo, nb_quant, verbose, C, do_sym)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# homeostasis : we compute P_cum and define different strategies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m     P_cum = update_P_cum(P_cum, sparse_code, eta_homeo,\n\u001b[0m\u001b[1;32m    523\u001b[0m                          nb_quant=nb_quant, verbose=verbose, C=C, do_sym=do_sym)\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tmp/SparseHebbianLearning/shl_scripts/shl_learn.py\u001b[0m in \u001b[0;36mupdate_P_cum\u001b[0;34m(P_cum, code, eta_homeo, C, nb_quant, do_sym, verbose)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m     \"\"\"\n\u001b[0;32m--> 656\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0meta_homeo\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m         \u001b[0mP_cum_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_P_cum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_quant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_quant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_sym\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_sym\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0mP_cum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0meta_homeo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mP_cum\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meta_homeo\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mP_cum_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tmp/SparseHebbianLearning/shl_scripts/shl_learn.py\u001b[0m in \u001b[0;36mget_P_cum\u001b[0;34m(code, C, nb_quant, do_sym, verbose)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_filter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m         \u001b[0;31m# note: the last bin includes 1, while this value is impossible (pc==1 <=> C=infinite)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_c\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcode_bins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/numpy/lib/histograms.py\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(a, bins, range, normed, weights, density)\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBLOCK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mBLOCK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                 \u001b[0mcum_n\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0m_search_sorted_inclusive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_edges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mzero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mntype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/numpy/lib/histograms.py\u001b[0m in \u001b[0;36m_search_sorted_inclusive\u001b[0;34m(a, v)\u001b[0m\n\u001b[1;32m    389\u001b[0m     return np.concatenate((\n\u001b[1;32m    390\u001b[0m         \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m     ))\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "experiments.scan(variable='eta', list_figures=list_figures, display='')\n",
    "plt.show()\n",
    "\n",
    "for display_variable in display_variables:\n",
    "    fig, ax = experiments.scan(variable='eta', list_figures=[], display='dynamic', display_variable=display_variable)\n",
    "    plt.show()\n",
    "\n",
    "for display_variable in display_variables:\n",
    "    fig, ax = experiments.scan(variable='eta', list_figures=[], display='final', display_variable=display_variable)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## comparing the result of learning with different sparse algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T08:31:43.582849Z",
     "start_time": "2018-09-26T08:03:15.323Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for display_variable in display_variables:          \n",
    "    fig, ax = None, None\n",
    "    for algorithm in ['lasso_lars', 'lasso_cd', 'lars', 'omp', 'mp']: # 'threshold', \n",
    "        opts = dict(homeo_method='None', learning_algorithm=algorithm, verbose=0)\n",
    "\n",
    "        experiments = SHL_set(opts, tag=tag + ' - algorithm={}'.format(algorithm))\n",
    "        experiments.scan(variable='eta', list_figures=list_figures, display='')\n",
    "        fig, ax = experiments.scan(variable='eta', list_figures=[], display='final', fig=fig, ax=ax, label=algorithm, display_variable=display_variable)   \n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU time as a function of the number of iterations\n",
    "\n",
    "Should be linear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T08:31:43.584356Z",
     "start_time": "2018-09-26T08:03:15.326Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for variable in ['n_iter', 'batch_size']:#, 'patch_width']:\n",
    "    experiments.scan(variable=variable, list_figures=list_figures, display='')\n",
    "    for display_variable in display_variables:\n",
    "        fig_error, ax_error = experiments.scan(variable=variable, list_figures=[], display='dynamic', display_variable=display_variable)\n",
    "        plt.show()\n",
    "    for display_variable in display_variables:\n",
    "        fig, ax = experiments.scan(list_figures=[], variable=variable, display='final', display_variable=display_variable)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## effect of the size of imagelet\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "experiments.scan(variable='patch_width', list_figures=list_figures, display='')\n",
    "fig_error, ax_error = experiments.scan(variable='patch_width', base=4, N_scan=5, list_figures=[], display='dynamic')\n",
    "plt.show()\n",
    "for display_variable in display_variables:\n",
    "    fig, ax = experiments.scan(list_figures=[], variable='patch_width', base=4, N_scan=5, display='final', display_variable=display_variable)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T08:31:43.585860Z",
     "start_time": "2018-09-26T08:03:15.359Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext version_information\n",
    "%version_information numpy, matplotlib, shl_scripts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "99px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
