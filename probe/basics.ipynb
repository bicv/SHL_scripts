{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Hebbian Learning: basics\n",
    "\n",
    "We are interested here in learning the \"optimal\" components of a set of images (let's say some \"natural\", usual images). As there is no supervisor to guide the learning, this is called unsupervised learning. Our basic hypothesis to find the best (\"optimal\") components will be to assume that *a priori* the most sparse is more plausible. We will implement the derived algorithm in this set of scripts.\n",
    "\n",
    "Here, we will show the basic operations that are implemented in this package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T14:33:35.933067Z",
     "start_time": "2018-09-26T14:33:35.908956Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T14:33:36.318894Z",
     "start_time": "2018-09-26T14:33:35.936028Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiments\n",
    "\n",
    "To test and control for the role of different parameters, we will have a first object (in the [shl_experiments.py](https://github.com/bicv/SparseHebbianLearning/blob/master/shl_scripts/shl_experiments.py) script) that controls a learning experiment. It contains all relevant parameters, but can also keep a trace of the history of some statistics. This is useful to compare the relative efficiency of the different solutions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T14:33:36.343925Z",
     "start_time": "2018-09-26T14:33:36.321736Z"
    }
   },
   "outputs": [],
   "source": [
    "matname = 'basics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T14:33:36.398634Z",
     "start_time": "2018-09-26T14:33:36.346835Z"
    }
   },
   "outputs": [],
   "source": [
    "from shl_scripts.shl_experiments import SHL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T14:33:36.421187Z",
     "start_time": "2018-09-26T14:33:36.400751Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on SHL in module shl_scripts.shl_experiments object:\n",
      "\n",
      "class SHL(builtins.object)\n",
      " |  Base class to define SHL experiments:\n",
      " |      - initialization\n",
      " |      - coding and learning\n",
      " |      - visualization\n",
      " |      - quantitative analysis\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, height=256, width=256, patch_width=18, N_patches=65536, datapath='../database/', name_database='kodakdb', do_mask=True, do_bandpass=True, over_patches=16, patch_ds=1, n_dictionary=441, learning_algorithm='mp', fit_tol=None, l0_sparseness=13, alpha_MP=1.0, one_over_F=True, n_iter=1025, eta=0.007, beta1=0.9, beta2=0.999, epsilon=1e-08, do_precision=False, eta_precision=0.0005, homeo_method='HEH', eta_homeo=0.02, alpha_homeo=0.08, C=3.0, nb_quant=128, P_cum=None, do_sym=False, seed=42, patch_norm=False, batch_size=1024, record_each=32, record_num_batches=1024, n_image=None, DEBUG_DOWNSCALE=1, verbose=0, cache_dir='cache_dir')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  code(self, data, dico, coding_algorithm='mp', matname=None, P_cum=None, fit_tol=None, l0_sparseness=None)\n",
      " |  \n",
      " |  decode(self, sparse_code, dico)\n",
      " |  \n",
      " |  get_data(self, matname=None, patch_width=None)\n",
      " |  \n",
      " |  learn_dico(self, dictionary=None, precision=None, P_cum=None, data=None, matname=None, record_each=None, folder_exp=None, list_figures=[], fig_kwargs={'fig': None, 'ax': None})\n",
      " |  \n",
      " |  plot_error(self, dico, **fig_kwargs)\n",
      " |  \n",
      " |  plot_variance(self, sparse_code, **fig_kwargs)\n",
      " |  \n",
      " |  plot_variance_histogram(self, sparse_code, **fig_kwargs)\n",
      " |  \n",
      " |  show_Pcum(self, dico, title=None, verbose=False, n_yticks=21, alpha=0.05, c='g', **fig_kwargs)\n",
      " |  \n",
      " |  show_dico(self, dico, data=None, title=None, **fig_kwargs)\n",
      " |  \n",
      " |  show_dico_in_order(self, dico, data=None, title=None, **fig_kwargs)\n",
      " |  \n",
      " |  time_plot(self, dico, variable='kurt', N_nosample=1, **fig_kwargs)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shl = SHL(homeo_method='HAP', DEBUG_DOWNSCALE=1, verbose=10)\n",
    "help(shl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T14:33:36.565338Z",
     "start_time": "2018-09-26T14:33:36.423442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 lolo  staff  231154688 Sep 26 13:33 cache_dir/basics_coding.npy\r\n",
      "-rw-r--r--  1 lolo  staff  134185088 Sep 26 13:07 cache_dir/basics_data.npy\r\n",
      "-rw-r--r--  1 lolo  staff          0 Sep 26 16:28 cache_dir/basics_dico.pkl_lock\r\n",
      "-rw-r--r--  1 lolo  staff          0 Sep 26 16:28 cache_dir/basics_dico.pkl_lock_pid-6569_host-ada\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l {shl.cache_dir}/{matname}*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T14:33:36.826850Z",
     "start_time": "2018-09-26T14:33:36.568019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 lolo  staff  231154688 Sep 26 13:33 cache_dir/basics_coding.npy\r\n",
      "-rw-r--r--  1 lolo  staff  134185088 Sep 26 13:07 cache_dir/basics_data.npy\r\n"
     ]
    }
   ],
   "source": [
    "!rm {shl.cache_dir}/{matname}*pkl*\n",
    "!ls -l {shl.cache_dir}/{matname}*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T14:33:37.036419Z",
     "start_time": "2018-09-26T14:33:36.829097Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data..loading the data called : cache_dir/basics_data\n",
      "Data is of shape : (65520, 256) - done in 0.08s.\n",
      "number of patches, size of patches =  (65520, 256)\n",
      "average of patches =  -4.193836974888984e-19  +/-  0.01106396040570928\n",
      "average energy of data =  4.846976510135289 +/- 1.457199891149408\n"
     ]
    }
   ],
   "source": [
    "data = shl.get_data(matname=matname)\n",
    "print('number of patches, size of patches = ', data.shape)\n",
    "print('average of patches = ', data.mean(), ' +/- ', data.mean(axis=1).std())\n",
    "SE = np.sqrt(np.sum(data**2, axis=1))\n",
    "print('average energy of data = ', SE.mean(), '+/-', SE.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learning\n",
    "\n",
    "The actual learning is done in a second object (here ``dico``) from which we can access another set of properties and functions  (see the [shl_learn.py](https://github.com/bicv/SparseHebbianLearning/blob/master/shl_scripts/shl_learn.py) script):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-26T14:33:35.910Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cache found cache_dir/basics_dico.pkl: Learning the dictionary with algo = mp \n",
      " Training on 65520 patches\n",
      "Iteration   1 /   1025 (elapsed time:   1s,   0mn   1s)\n",
      "Iteration  33 /   1025 (elapsed time:  30s,   0mn  30s)\n",
      "Iteration  65 /   1025 (elapsed time:  62s,   1mn   2s)\n",
      "Iteration  97 /   1025 (elapsed time:  99s,   1mn  39s)\n",
      "Iteration  129 /   1025 (elapsed time:  142s,   2mn  22s)\n",
      "Iteration  161 /   1025 (elapsed time:  185s,   3mn   5s)\n",
      "Iteration  193 /   1025 (elapsed time:  222s,   3mn  42s)\n",
      "Iteration  225 /   1025 (elapsed time:  261s,   4mn  21s)\n",
      "Iteration  257 /   1025 (elapsed time:  298s,   4mn  58s)\n",
      "Iteration  289 /   1025 (elapsed time:  334s,   5mn  34s)\n",
      "Iteration  321 /   1025 (elapsed time:  369s,   6mn   9s)\n",
      "Iteration  353 /   1025 (elapsed time:  404s,   6mn  44s)\n"
     ]
    }
   ],
   "source": [
    "list_figures = ['show_dico', 'time_plot_error', 'time_plot_logL', 'show_Pcum']#, 'plot_variance',  'plot_variance_histogram',  'time_plot_prob',  'time_plot_kurt',  'time_plot_var']\n",
    "dico = shl.learn_dico(data=data, list_figures=list_figures, matname=matname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-26T14:33:35.915Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "help(dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-26T14:33:35.919Z"
    }
   },
   "outputs": [],
   "source": [
    "print('size of dictionary = (number of filters, size of imagelets) = ', dico.dictionary.shape)\n",
    "print('average of filters = ',  dico.dictionary.mean(axis=1).mean(), \n",
    "      '+/-',  dico.dictionary.mean(axis=1).std())\n",
    "SE = np.sqrt(np.sum(dico.dictionary**2, axis=1))\n",
    "print('average energy of filters = ', SE.mean(), '+/-', SE.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coding\n",
    "\n",
    "The learning itself is done via a gradient descent but is highly dependent on the coding / decoding algorithm. This belongs to a another function (in the [shl_encode.py](https://github.com/bicv/SparseHebbianLearning/blob/master/shl_scripts/shl_encode.py) script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-26T14:33:35.926Z"
    }
   },
   "outputs": [],
   "source": [
    "sparse_code = shl.code(data, dico, matname=matname, l0_sparseness=45)\n",
    "print('number of codes, size of codewords = ', sparse_code.shape)\n",
    "print('average of codewords = ', sparse_code.mean())\n",
    "print('average energy of codewords = ', sparse_code.std(axis=0).mean())\n",
    "print('std of the average of individual patches = ', sparse_code.mean(axis=0).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-26T14:33:35.930Z"
    }
   },
   "outputs": [],
   "source": [
    "patches = sparse_code @ dico.dictionary\n",
    "print('number of codes, size of reconstructed images = ', patches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-26T14:33:35.933Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "error = data - patches\n",
    "print('average of residual patches = ', error.mean(), '+/-', error.mean(axis=1).std())\n",
    "SE = np.sqrt(np.sum(error**2, axis=1))\n",
    "print('average energy of residual = ', SE.mean(), '+/-', SE.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-26T14:33:35.936Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext version_information\n",
    "%version_information numpy, shl_scripts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
