{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sparse Hebbian Learning with Histogram Equalization Homeostasis : testing with different learning rates\n",
    "\n",
    "In this notebook, we test the convergence of SparseNet as a function of different learning parameters. This shows the relative robusteness of this method according to the coding parameters, but also the importance of homeostasis to obtain an efficient set of filters.\n",
    "\n",
    "It uses the full homeostasis layer (by setting ``alpha_homeo=0.``) - to be compared to a smoother Olshausen-like homeostasis.\n",
    "\n",
    "See also :\n",
    "* http://blog.invibe.net/posts/2015-05-05-reproducing-olshausens-classical-sparsenet.html for a description of how SparseNet is implemented in the scikit-learn package\n",
    "* http://blog.invibe.net/posts/2015-05-06-reproducing-olshausens-classical-sparsenet-part-2.html for a descrtiption of how we managed to implement the homeostasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-19T19:54:33.525533Z",
     "start_time": "2018-01-19T19:54:33.490155Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-19T19:54:34.375284Z",
     "start_time": "2018-01-19T19:54:33.528106Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-19T19:54:34.834284Z",
     "start_time": "2018-01-19T19:54:34.378015Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data..loading the data called : /tmp/data_cache/data_data\n",
      "Data is of shape : (81920, 256) - done in 0.38s.\n"
     ]
    }
   ],
   "source": [
    "from shl_scripts.shl_experiments import SHL\n",
    "\n",
    "list_figures = ['show_dico', 'time_plot_prob']# 'plot_variance',  'plot_variance_histogram', ,  'time_plot_kurt',  'time_plot_var']DEBUG_DOWNSCALE, verbose = 10, 0\n",
    "DEBUG_DOWNSCALE, verbose = 10, 100\n",
    "DEBUG_DOWNSCALE, verbose = 1, 10\n",
    "N_scan = 7\n",
    "tag = 'HEH'\n",
    "homeo_params = dict(eta_homeo=0.05, alpha_homeo=0.02, C=5., nb_quant=128, P_cum=None)\n",
    "opts = dict(DEBUG_DOWNSCALE=DEBUG_DOWNSCALE, homeo_method=tag, homeo_params=homeo_params, verbose=verbose)\n",
    "data = SHL(**opts).get_data(matname='data')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-01-19T19:54:33.499Z"
    }
   },
   "source": [
    "!rm -fr data_cache/{tag}*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## different learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-01-19T19:54:33.508Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cache found /tmp/data_cache/HEH - eta=0.005000000000000001_dico.pkl: Learning the dictionary with algo = mp \n",
      " Training on 81920 patches... Iteration   0 /   4096 (elapsed time:   1s,  0.0mn)\n",
      "(128,) (576,) (128,)\n",
      "(128,) (576,) (128,)\n",
      "(128,) (576,) (128,)\n",
      "(128,) (576,) (128,)\n",
      "Iteration  410 /   4096 (elapsed time:  8219s,  136.0mn)\n",
      "(128,) (576,) (128,)\n",
      "(128,) (576,) (128,)\n",
      "(128,) (576,) (128,)\n",
      "Iteration  820 /   4096 (elapsed time:  14879s,  247.0mn)\n",
      "(128,) (576,) (128,)\n",
      "(128,) (576,) (128,)\n",
      "(128,) (576,) (128,)\n",
      "Iteration  1230 /   4096 (elapsed time:  21484s,  358.0mn)\n",
      "(128,) (576,) (128,)\n",
      "(128,) (576,) (128,)\n",
      "(128,) (576,) (128,)\n",
      "Iteration  1640 /   4096 (elapsed time:  28085s,  468.0mn)\n",
      "(128,) (576,) (128,)\n",
      "(128,) (576,) (128,)\n",
      "(128,) (576,) (128,)\n"
     ]
    }
   ],
   "source": [
    "for eta in np.logspace(-1, 1, N_scan, base=10)*SHL(**opts).eta['eta']:\n",
    "    shl = SHL(**opts)\n",
    "    matname = tag + ' - eta={}'.format(eta)\n",
    "    shl.eta.update(eta=eta)\n",
    "    dico = shl.learn_dico(data=data, matname=matname, list_figures=list_figures)    \n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## different homeostatic learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-01-19T19:54:33.511Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "homeo_params = SHL(**opts).homeo_params\n",
    "for eta_homeo in np.logspace(-1, 1, N_scan, base=10)*homeo_params['eta_homeo']:\n",
    "    shl = SHL(**opts)    \n",
    "    matname = tag + ' - eta_homeo={}'.format(eta_homeo)\n",
    "    shl.homeo_params.update(eta_homeo=eta_homeo)\n",
    "    dico = shl.learn_dico(data=data, matname=matname, list_figures=list_figures)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## different sparseness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-01-19T19:54:33.517Z"
    }
   },
   "outputs": [],
   "source": [
    "2**np.arange(N_scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-01-19T19:54:33.522Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for l0_sparseness in 2**np.arange(N_scan):\n",
    "    shl = SHL(**opts, l0_sparseness=l0_sparseness)\n",
    "    matname = tag + ' - l0_sparseness={l0_sparseness}'.format(l0_sparseness=l0_sparseness)\n",
    "    dico = shl.learn_dico(data=data, matname=matname, list_figures=list_figures)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-01-19T19:54:33.526Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext version_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-01-19T19:54:33.529Z"
    }
   },
   "outputs": [],
   "source": [
    "%version_information numpy, shl_scripts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {
    "height": "81px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
