{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sparse Hebbian Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T15:14:02.351662Z",
     "start_time": "2018-09-11T15:14:02.329953Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T15:14:04.252601Z",
     "start_time": "2018-09-11T15:14:02.355690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This is a collection of python scripts to test learning strategies to efficiently code natural image patches.  This is here restricted  to the framework of the [SparseNet algorithm from Bruno Olshausen](http://redwood.berkeley.edu/bruno/sparsenet/).\n"
     ]
    }
   ],
   "source": [
    "%run setup.py --description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T15:14:04.287843Z",
     "start_time": "2018-09-11T15:14:04.256460Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-11T15:14:02.368Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data..loading the data called : probe/cache_dir/data_data\n",
      "Data is of shape : (65520, 324) - done in 1.28s.\n",
      "No cache found probe/cache_dir/HULK_homeo_dico.pkl: Learning the dictionary with algo = mp \n",
      " Training on 65520 patches\n",
      "Iteration   1 /   1025 (elapsed time:   1s,   0mn   1s)\n",
      "Iteration  33 /   1025 (elapsed time:  28s,   0mn  28s)\n",
      "Iteration  65 /   1025 (elapsed time:  55s,   0mn  55s)\n",
      "Iteration  97 /   1025 (elapsed time:  80s,   1mn  20s)\n"
     ]
    }
   ],
   "source": [
    "from shl_scripts.shl_experiments import SHL\n",
    "\n",
    "DEBUG_DOWNSCALE, verbose = 10, 0\n",
    "DEBUG_DOWNSCALE, verbose = 10, 10\n",
    "DEBUG_DOWNSCALE, verbose = 1, 10\n",
    "\n",
    "list_figures = ['show_dico', 'plot_variance',  'plot_variance_histogram',  'time_plot_prob',  'time_plot_kurt',  'time_plot_var', 'time_plot_MC']\n",
    "opts= dict(DEBUG_DOWNSCALE=DEBUG_DOWNSCALE, verbose=verbose, cache_dir='probe/cache_dir', datapath='../database')\n",
    "shl = SHL(**opts)\n",
    "tag = 'HULK'\n",
    "data = shl.get_data(matname='data')\n",
    "dico = shl.learn_dico(data=data, matname=tag + '_homeo', list_figures=list_figures)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### control: learning without homeostasis\n",
    "\n",
    "During the learning, to avoid divergence, the norm of the filters is shunted to $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-11T15:14:02.371Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shl = SHL(homeo_method='None', **opts)\n",
    "matname = tag + '_nohomeo'\n",
    "dico = shl.learn_dico(data=data, matname=matname, list_figures=list_figures) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Hebbian Learning : reproducing SparseNet\n",
    "\n",
    "If we test the convergence of SparseNet as a function of different learning parameters, it shows the relative robusteness of this method according to the coding parameters, but also the importance of homeostasis to obtain an efficient set of filters:\n",
    "\n",
    "See :\n",
    "* http://blog.invibe.net/posts/2015-05-05-reproducing-olshausens-classical-sparsenet.html for a description of how SparseNet is implemented in the ``scikit-learn`` package\n",
    "* http://blog.invibe.net/posts/2015-05-06-reproducing-olshausens-classical-sparsenet-part-2.html for a descrtiption of how we managed to implement the homeostasis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-11T15:14:02.373Z"
    }
   },
   "outputs": [],
   "source": [
    "!rm -fr {shl.cache_dir}/{tag}*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-11T15:14:02.374Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls {shl.cache_dir}/HULK_*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-11T15:14:02.376Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext version_information\n",
    "%version_information numpy, shl_scripts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "99px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
